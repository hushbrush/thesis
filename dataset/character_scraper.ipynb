{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1529e3f9-7bd4-45d7-aba7-9cfb1de44955",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from playwright.async_api import async_playwright\n",
    "import re\n",
    "import unicodedata\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f3034d6a-8a90-4f13-ae25-f2a9818da44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def normalize_name(name):\n",
    "    name = name.lower()\n",
    "    name = unicodedata.normalize('NFKD', name).encode('ASCII', 'ignore').decode()\n",
    "    name = re.sub(r'[^a-z]', '', name)\n",
    "    return name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f139e9be-194b-462e-8f27-3d29cb093cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def infer_gender(paragraph):\n",
    "    paragraph = paragraph.lower()\n",
    "    female_keywords = [\"daughter\", \"wife\", \"queen\", \"princess\", \"goddess\", \"lady\", \"mistress\", \"her name\", \"she was\", \"she is\"]\n",
    "    male_keywords = [\"son\", \"husband\", \"king\", \"prince\", \"god\", \"his name\", \"he was\", \"he is\"]\n",
    "\n",
    "    for word in female_keywords:\n",
    "        if word in paragraph:\n",
    "            return \"female\"\n",
    "    for word in male_keywords:\n",
    "        if word in paragraph:\n",
    "            return \"male\"\n",
    "    return \"unknown\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c2b817fe-5682-4284-a262-2abb830e4e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def scrape_characters_playwright(slug):\n",
    "    url = f\"https://www.sparknotes.com/lit/{slug}/characters/\"\n",
    "    characters = []\n",
    "\n",
    "    async with async_playwright() as p:\n",
    "        browser = await p.chromium.launch(headless=True)\n",
    "        page = await browser.new_page()\n",
    "        try:\n",
    "            print(f\"Opening: {url}\")\n",
    "            await page.goto(url, timeout=10000)\n",
    "            await page.wait_for_selector(\"h3\", timeout=5000)\n",
    "\n",
    "            headers = await page.query_selector_all(\"h3\")\n",
    "            for header in headers:\n",
    "                char_name = (await header.inner_text()).strip()\n",
    "                next_p = await header.evaluate_handle(\"el => el.nextElementSibling\")\n",
    "                if next_p:\n",
    "                    bio_text = (await next_p.evaluate(\"el => el.textContent\")).strip()\n",
    "                    gender = infer_gender(bio_text)\n",
    "                    characters.append({\n",
    "                        \"name\": char_name,\n",
    "                        \"normalized\": normalize_name(char_name),\n",
    "                        \"gender\": gender,\n",
    "                        \"bio\": bio_text\n",
    "                    })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error scraping {slug}: {e}\")\n",
    "        finally:\n",
    "            await browser.close()\n",
    "\n",
    "    return characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c991f1c6-d32f-4bef-b672-a2c69eb69ef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening: https://www.sparknotes.com/lit/odyssey/characters/\n",
      "Error scraping odyssey: Page.wait_for_selector: Timeout 5000ms exceeded.\n",
      "Call log:\n",
      "  - waiting for locator(\"h3\") to be visible\n",
      "\n"
     ]
    }
   ],
   "source": [
    "characters_odyssey = await scrape_characters_playwright(\"odyssey\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "99754ddf-a289-484f-a805-32fed029463c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(characters_odyssey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4c0ceef5-9f4b-41fb-8f26-b98e21089dd4",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'epic_books5.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mepic_books5.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'epic_books5.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"epic_books5.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "da5e002a-b718-424c-bd2b-4a4917bab451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wikipedia\n",
      "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: beautifulsoup4 in ./anaconda3/lib/python3.10/site-packages (from wikipedia) (4.12.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in ./anaconda3/lib/python3.10/site-packages (from wikipedia) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./anaconda3/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./anaconda3/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./anaconda3/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./anaconda3/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (1.26.15)\n",
      "Requirement already satisfied: soupsieve>1.2 in ./anaconda3/lib/python3.10/site-packages (from beautifulsoup4->wikipedia) (2.4)\n",
      "Building wheels for collected packages: wikipedia\n",
      "  Building wheel for wikipedia (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11680 sha256=c18d4e4dabcd0b61fa8de732b236c932e30f8a893f8e9f285b10603c0bb34936\n",
      "  Stored in directory: /Users/harshitachakravadhanula./Library/Caches/pip/wheels/b2/7f/26/524faff9145e274da278dc97d63ab0bfde1f791ecf101a9c95\n",
      "Successfully built wikipedia\n",
      "Installing collected packages: wikipedia\n",
      "Successfully installed wikipedia-1.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install wikipedia\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4bb2203f-4ef3-4195-86da-bec44605cd82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://en.wikipedia.org/wiki/List_of_Adventures_in_Odyssey_characters\n",
      "https://en.wikipedia.org/wiki/List_of_characters_in_the_Mahabharata\n",
      "https://en.wikipedia.org/wiki/List_of_Shahnameh_characters\n"
     ]
    }
   ],
   "source": [
    "import wikipedia\n",
    "\n",
    "def get_character_page(title):\n",
    "    try:\n",
    "        results = wikipedia.search(f\"{title} characters\")\n",
    "        for result in results:\n",
    "            if \"character\" in result.lower() and title.lower() in result.lower():\n",
    "                return wikipedia.page(result).url\n",
    "        return wikipedia.page(results[0]).url  # fallback\n",
    "    except Exception as e:\n",
    "        print(f\"Failed for {title}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Example\n",
    "print(get_character_page(\"Odyssey\"))\n",
    "print(get_character_page(\"Mahabharata\"))\n",
    "print(get_character_page(\"Shahnameh\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "465ce420-4397-4886-bb67-bd9a34f22feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_character_page2(title):\n",
    "    try:\n",
    "        query = f\"{title} characters\"\n",
    "        results = wikipedia.search(query)\n",
    "        title_lower = title.lower()\n",
    "\n",
    "        for result in results:\n",
    "            if \"character\" in result.lower() and title_lower in result.lower():\n",
    "                return wikipedia.page(result).url\n",
    "\n",
    "        # fallback: try to find *any* list of characters\n",
    "        for result in results:\n",
    "            if \"character\" in result.lower():\n",
    "                return wikipedia.page(result).url\n",
    "\n",
    "        # ultimate fallback\n",
    "        return wikipedia.page(results[0]).url\n",
    "    except Exception as e:\n",
    "        print(f\"Failed for {title}: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b5c71b3e-52fe-4de0-83ec-25bf95f9a016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://en.wikipedia.org/wiki/List_of_Adventures_in_Odyssey_characters\n",
      "https://en.wikipedia.org/wiki/List_of_characters_in_the_Mahabharata\n",
      "https://en.wikipedia.org/wiki/List_of_Shahnameh_characters\n",
      "https://en.wikipedia.org/wiki/Divine_Comedy_Illustrated_by_Botticelli\n"
     ]
    }
   ],
   "source": [
    "print(get_character_page2(\"Odyssey\"))        # Should skip Adventures in Odyssey\n",
    "print(get_character_page2(\"Mahabharata\"))    # ✅\n",
    "print(get_character_page2(\"Shahnameh\"))      # ✅\n",
    "print(get_character_page2(\"Divine Comedy\"))  # Let's see what it gives you\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "aab95c7d-4b7b-44d0-8b3c-a507a02db524",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def scrape_shmoop_characters(slug):\n",
    "    url = f\"https://www.shmoop.com/study-guides/{slug}/characters.html\"\n",
    "    characters = []\n",
    "\n",
    "    async with async_playwright() as p:\n",
    "        browser = await p.chromium.launch(headless=True)\n",
    "        page = await browser.new_page()\n",
    "        try:\n",
    "            print(f\"Opening: {url}\")\n",
    "            await page.goto(url, timeout=15000)\n",
    "            await page.wait_for_selector(\".panel-heading h4\", timeout=8000)\n",
    "\n",
    "            headings = await page.query_selector_all(\".panel-heading h4\")\n",
    "\n",
    "            for heading in headings:\n",
    "                char_name = (await heading.inner_text()).strip()\n",
    "                body = await heading.evaluate_handle(\"el => el.parentElement.nextElementSibling\")\n",
    "                if body:\n",
    "                    bio_text = (await body.evaluate(\"el => el.textContent\")).strip()\n",
    "                    gender = infer_gender(bio_text)\n",
    "                    characters.append({\n",
    "                        \"name\": char_name,\n",
    "                        \"normalized\": normalize_name(char_name),\n",
    "                        \"gender\": gender,\n",
    "                        \"bio\": bio_text\n",
    "                    })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error scraping {slug}: {e}\")\n",
    "        finally:\n",
    "            await browser.close()\n",
    "\n",
    "    return characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6decc879-8c67-46fe-91b7-29d8a00fd535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening: https://www.shmoop.com/study-guides/gilgamesh/characters.html\n",
      "{'name': 'Gilgamesh', 'normalized': 'gilgamesh', 'gender': 'male', 'bio': \"The hero of our tale: a cocky, selfish young king who befriends a half man/half beast, goes on fantastic adventures with him. When his new, beloved friend dies, Gilgamesh realizes there's no room i...\"}\n",
      "{'name': 'Enkidu', 'normalized': 'enkidu', 'gender': 'male', 'bio': 'Half-man/half-beast bestie of Gilgamesh. He basically symbolizes the natural, non-civilized world. He faces an early death as punishment from the gods for all the trouble that he and Gilgamesh got...'}\n",
      "{'name': 'Utanapishtim', 'normalized': 'utanapishtim', 'gender': 'male', 'bio': 'A human given immortality who lives on the other side of earth—literally. Gilgamesh visits him to discover the secret of immortality, but ends up empty-handed.The Gods Told You What?Utanapishtim...'}\n",
      "{'name': 'Shamhat', 'normalized': 'shamhat', 'gender': 'unknown', 'bio': \"Even though she only appears in Tablets 1 and 2 (plus getting cursed and blessed in Tablet 7), Shamhat is a major female character who plays a pivotal role in the story. She uses her wily woman's w...\"}\n",
      "{'name': 'Ishtar', 'normalized': 'ishtar', 'gender': 'female', 'bio': 'Ishtar, the goddess of love and war, has a small, devastating role in the epic. She basically lets all fire and brimstone loose, which leads to a clash with Enkidu and Gilgamesh, which in turn lead...'}\n",
      "{'name': 'Siduri', 'normalized': 'siduri', 'gender': 'unknown', 'bio': 'She runs the bar in hell, so to speak. And, depending on what version you read, she may or may not give Gilgamesh some advice on what matters most in life.Bar Wench ExtraordinaireSiduri is the tave...'}\n",
      "{'name': 'Humbaba', 'normalized': 'humbaba', 'gender': 'male', 'bio': \"Humbaba is the monster who guards the Cedar Forest. Being a monster and all, he isn't the most complicated character, although he can do a neat trick where he changes his faces, and apparently it i...\"}\n",
      "{'name': 'Ninsun', 'normalized': 'ninsun', 'gender': 'unknown', 'bio': \"The mother of Gilgamesh. And, for heaven's sake, don't take parenting advice from this gal.Gilgamesh's father, Lugalbanda, was a mortal human, dead before the beginning of the epic. Much like Theti...\"}\n",
      "{'name': 'Shamash', 'normalized': 'shamash', 'gender': 'male', 'bio': \"The Sun-god and Gilgamesh's main go-to-god.It must be nice to have a personal god. Shamash, the sun-god, basically seems to hang around to help out Gilgamesh and Enkidu. We first get important sign...\"}\n",
      "{'name': 'Anu', 'normalized': 'anu', 'gender': 'male', 'bio': \"Anu is the sky-god in Mesopotamian mythology and the doting daddy of Ishtar.Being the sky-god and all, Anu probably has a lot on his plate. So, he doesn't have a very big role in The Epic of Gilgam...\"}\n",
      "{'name': 'Enlil', 'normalized': 'enlil', 'gender': 'male', 'bio': 'Enlil is the king of the gods and the one who grants immortality to the Utanapishtims.As you might expect for a king of the gods, Enlil is a little hard to figure out. In Tablet 2, when Gilgamesh t...'}\n",
      "{'name': \"Utanapishtim's Wife\", 'normalized': 'utanapishtimswife', 'gender': 'female', 'bio': \"Nice, also immortal, wife of the grumpy immortal dude. She bakes bread and urges Utanapishtim to tell Gilgamesh about the plant that makes you young again.Utanapishtim's wife has a small role in th...\"}\n",
      "{'name': 'Ea', 'normalized': 'ea', 'gender': 'male', 'bio': \"Trickster god who keeps Utanapishtim from dying in the flood by giving him the inside scoop on Ea's flood plans.The god Ea features in the Flood story on Tablet 11. According to Utanapishtim, Ea he...\"}\n",
      "{'name': 'Aruru', 'normalized': 'aruru', 'gender': 'female', 'bio': 'Goddess who makes Enkidu and places him in the wilderness.Although she has a very important role in Mesopotamian mythology (she was the creator of humankind), Aruru has a very small role in the Epi...'}\n",
      "{'name': 'Trapper', 'normalized': 'trapper', 'gender': 'unknown', 'bio': 'The trapper has a very small part in the story. Basically, his purpose is to bring Shamhat into the wilderness, thus setting in motion the chain of events that makes Enkidu become human and leads t...'}\n",
      "{'name': \"The Trapper's Father\", 'normalized': 'thetrappersfather', 'gender': 'unknown', 'bio': \"We meet the trapper's father after the trapper gets freaked out by seeing Enkidu at the watering hole. The trapper goes to his dad to ask him for advice. His dad tells him to go to Uruk and get Gil...\"}\n",
      "{'name': 'Antum', 'normalized': 'antum', 'gender': 'female', 'bio': 'The goddess Antum is the wife of Anu, the sky-god. We see her briefly in Tablet 6, when Ishtar goes up to the heavens to borrow the Bull of Heaven, in order to punish Gilgamesh for rejecting her. (...'}\n"
     ]
    }
   ],
   "source": [
    "characters = await scrape_shmoop_characters(\"gilgamesh\")\n",
    "for c in characters: print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5085ff83-4e69-4c32-a65e-9c1ea4c96e74",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m characters_list \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m title \u001b[38;5;129;01min\u001b[39;00m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource_title\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mdropna()\u001b[38;5;241m.\u001b[39munique():\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScraping: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtitle\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "characters_list = []\n",
    "\n",
    "for title in df[\"source_title\"].dropna().unique():\n",
    "    try:\n",
    "        print(f\"Scraping: {title}\")\n",
    "        char_info = await scrape_shmoop_characters(title)\n",
    "        characters_list.append({\n",
    "            \"source_title\": title,\n",
    "            \"characters_info\": char_info\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping {title}: {e}\")\n",
    "        characters_list.append({\n",
    "            \"source_title\": title,\n",
    "            \"characters_info\": None\n",
    "        })\n",
    "\n",
    "characters = pd.DataFrame(characters_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0dbd0e-bffa-44d6-802f-7b3699b7c2b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
